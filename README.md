# CoT-Compression
# ðŸ‘€ Introduction
In recent years, Large Language Models (LLMs) have significantly improved the solution capabilities of complex tasks, such as mathematical reasoning and logical reasoning, by introducing Chain-of-Thought (CoT) reasoning.However, CoT approaches typically rely on generating lengthy intermediate reasoning steps, leading to a surge in computational overhead, increased reasoning latency, and hindering their application in resource-constrained scenarios such as edge devices or real-time systems.To address this contradiction, researchers have proposed CoT compression techniques that aim to significantly reduce the inference cost while maintaining the model performance by optimising the inference paths, refining the key steps, or dynamically adjusting the computational complexity.Therefore, we maintain an up-to-date GitHub repository to track the latest progress in this rapidly evolving field.
# ðŸ“’ Table of Contents
- TokenSkip [[GitHub]](https://github.com/hemingkx/TokenSkip)
- Rho-1 [[GitHub]](https://github.com/microsoft/rho)
- SelectiveDPO(Principled Data Selection for Alignment: The Hidden Risks of Difficult Examples) [[GitHub]](https://github.com/glorgao/SelectiveDPO)
- CoT-Valve: Length-Compressible Chain-of-Thought Tuning [[pdf]](https://arxiv.org/abs/2502.09601)
- Chain of Draft: Thinking Faster by Writing Less [[pdf]](https://arxiv.org/abs/2502.18600)
- LightThinker: Thinking Step-by-Step Compression [[pdf]](https://arxiv.org/abs/2502.15589)
- Understanding Chain-of-Thought in LLMs through Information Theory [[pdf]](https://arxiv.org/abs/2411.11984)
- When More is Less: Understanding Chain-of-Thought Length in LLMs [[pdf]](https://arxiv.org/abs/2502.07266)
- Dynamic Chain-of-Thought: Towards Adaptive Deep Reasoning [[pdf]](https://arxiv.org/abs/2502.10428)
- Stepwise Perplexity-Guided Refinement for Efficient Chain-of-Thought Reasoning in Large Language Models [[pdf]](https://arxiv.org/abs/2502.13260)
- Distilling System 2 into System 1 [[pdf]](https://arxiv.org/abs/2502.10428)
- Efficiently Serving LLM Reasoning Programs with Certaindex [[pdf]](https://arxiv.org/abs/2412.20993)
- Fast Best-of-N Decoding via Speculative Rejection [[pdf]](https://arxiv.org/abs/2410.20290)
